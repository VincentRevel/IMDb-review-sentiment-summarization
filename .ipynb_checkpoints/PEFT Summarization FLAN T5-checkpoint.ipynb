{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e52a6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import time\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dab11f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "# Set the default device for tensors\n",
    "torch.cuda.set_device(0)  # Set the GPU you want to use if you have multiple GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb1e7c2",
   "metadata": {},
   "source": [
    "## 1 - Dataset and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c66c1797",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed8986ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66c83e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text from HTML tags\n",
    "def clean_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "    # Remove escape characters\n",
    "    text = re.sub(r'\\\\', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8cb12d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the text in the dataset\n",
    "for split in ['train', 'test', 'unsupervised']:\n",
    "    dataset[split] = dataset[split].map(lambda example: {'text': clean_text(example['text']), 'label': example['label']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "243b2c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='google/flan-t5-base'\n",
    "\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "original_tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4070cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(task=\"text2text-generation\", model=original_model, tokenizer=original_tokenizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58da012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_summary(input_text):\n",
    "    prompt = \"Summarize the following movie review.: \" + input_text + \"\\n\\nSentiment:\"\n",
    "    output = pipe(prompt, max_length=512)\n",
    "    return output[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a7c395a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m input_text \u001b[38;5;241m=\u001b[39m original_tokenizer\u001b[38;5;241m.\u001b[39mdecode(example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(input_text)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'example' is not defined"
     ]
    }
   ],
   "source": [
    "input_text = original_tokenizer.decode(example['input_ids'], skip_special_tokens=True)\n",
    "print(input_text)\n",
    "# prediction = calculate_sentiment(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34aeab31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "Summarize the following movie review.\n",
      "\n",
      "He who fights with monsters might take care lest he thereby become a monster. And if you gaze for long into an abyss, the abyss gazes also into you.<br /><br />Yes, this is from Nietzsche's Aphorism 146 from \"Beyond Good and Evil\". And that's what you find at the start of this movie.<br /><br />If you watch the whole movie, you will doubt if it was the message that the Ram Gopal Varma Production wanted to pass on. As the scenes crop up one by one, quite violent and at times puke-raking, the viewer is expected to forget the Nietzsche quote and think otherwise. That to deal with few people you need dedicated people like Sadhu Agashe who will have the licence to kill anyone, not just writing FIRs (something unworthy of the police to do, as we are made to believe).<br /><br />When TADA was repealed and the government wanted to pass newer and even more draconian laws, RGV's \"Satya\" did the required brain surgery without blood transfusion for the multiplex growing thinking urban crowd whose views matters in a democratic country like India. Within a year MCOCA was passed.<br /><br />When real life encounter specialist Daya Nayak 'became a monster on the path of fighting them' and was himself booked by MCOCA, \"Aab tak Chhappan\" was made to heed out \"false\" impression among the people about this. With it's \"you have to be a monster to save your nation\" approach.<br /><br />And people consumed it. No questions raised. Only praises and hopes that they get a Sadhu Agashe in their local police station who will solve all problems and hence let only milk and butter flow all over. Blood? You can ignore.<br /><br />Every time Israel attacks Palestine or Lebanon, we hear voices like \"India must also similarly attack Pakistan\". This movie is made for such psychopaths. If you don't give them this, they will probably die out of boredom and LSD and what not.<br /><br />Hence this game of the passion of hatred.\n",
      "\n",
      "Summary: \n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE IMDB SENTIMENT:\n",
      "negative\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "Aab tak Chhappan is a movie that is a bit too sappy for its own good.\n"
     ]
    }
   ],
   "source": [
    "index = 200\n",
    "\n",
    "text = dataset['test']['text'][index]\n",
    "label = dataset['test']['label'][index]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the following movie review.\n",
    "\n",
    "{text}\n",
    "\n",
    "Summary: \"\"\"\n",
    "\n",
    "inputs = original_tokenizer(prompt, return_tensors='pt', max_length=512, truncation=True)\n",
    "output = original_tokenizer.decode(\n",
    "    original_model.generate(\n",
    "        inputs[\"input_ids\"], \n",
    "        max_new_tokens=200,\n",
    "    )[0], \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "# Convert the label to \"negative\" if 0, and \"positive\" if 1\n",
    "sentiment_label = \"positive\" if label == 1 else \"negative\"\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE IMDB SENTIMENT:\\n{sentiment_label}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462b5fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
